{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 1\n",
    "\n",
    "The goal of this exercise is to model a function of the form\n",
    "$$ z = f \\left( (x - a)^2 + (y - b)^2 \\right), $$ \n",
    "with a Neural Network (NN). Practically, you are searching for a mapping from $\\mathbb{R}^2 \\rightarrow \\mathbb{R}$. Unfortunately, in the general case, you don't know the constant $a,b$ and the function $f$. However, you have a collection of data points $(x,y,z)$. \n",
    "\n",
    "1. Start by implementing a simple NN with linear layers that does not take into account of the function class. How hard is it to fit the data? \n",
    "\n",
    "2. Find a way to encode the data characteristics in the model. Is it still hard to fit the data? You can start by assuming that you know a and b.\n",
    "\n",
    "3. Study the effect of the sample. Decrease the amount of data in the training set. What do you observe?\n",
    "\n",
    "4. What about the case where you don't know a and b?\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Autoreload is to always reload the imported python files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Matplotlib inline allows to make plot inline with the notebook with Matplotlib\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import all packages\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from poutyne import Model, SKLearnMetrics\n",
    "from sklearn.metrics import r2_score, median_absolute_error\n",
    "from utils import metric_flatten, get_poutyne_callbacks, saferm\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# These line allows to select the first GPU of the machine or the CPU is not GPU is present\n",
    "cuda_device = 0\n",
    "device = torch.device(\"cuda:%d\" % cuda_device if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset generation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Assume you don't know the data generating function.\n",
    "# Later on assume you don't know a and b and try to recover them.\n",
    "a = 0.2 \n",
    "b = 0.8\n",
    "def func(xx,yy):\n",
    "    y = 2*np.cos( 3* ((xx-a)**2 + (yy-b)**2) )\n",
    "    return y\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lim = 1.5\n",
    "x = np.arange(-lim, lim, 0.03)\n",
    "y = np.arange(-lim, lim, 0.03)\n",
    "xx, yy = np.meshgrid(x, y, sparse=False)\n",
    "z = func(xx,yy)\n",
    "h = plt.contourf(x, y, z)\n",
    "plt.colorbar()\n",
    "plt.axis('scaled');\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## dataset creation\n",
    "def sample_generator_regression(n):\n",
    "    # RRandom sampling of points\n",
    "    x = np.random.rand(n, 2).astype(np.float32)*2*lim -lim\n",
    "    # compute the output\n",
    "    # we expand the dimension to have the size [n x 1], which will be the output shape of the NN.\n",
    "    y = np.expand_dims(func(x[:,0], x[:,1]),axis=1)\n",
    "    # Convertion to Pytorch tensors\n",
    "    return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "n_train = 1024\n",
    "\n",
    "train_data = sample_generator_regression(n_train)\n",
    "valid_data = sample_generator_regression(64)\n",
    "test_data = sample_generator_regression(128)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# It is very practical to transform our data into torch dataset\n",
    "train_dataset = TensorDataset(*train_data)\n",
    "valid_dataset = TensorDataset(*valid_data)\n",
    "test_dataset = TensorDataset(*test_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 1: Linear layer NN."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class LinearNet(nn.Module):\n",
    "    ### define you model here\n",
    "\n",
    "network = LinearNet()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define a poutyne model with optimizer, loss and metrics\n",
    "# model = Model (...)\n",
    "\n",
    "# optimization paramters\n",
    "optimization_kwargs = {}\n",
    "optimization_kwargs[\"batch_size\"] = 8\n",
    "optimization_kwargs[\"epochs\"] = 15\n",
    "\n",
    "# train the model\n",
    "# note that the function will load the model with best validation score at the end\n",
    "history = model.fit_dataset(train_dataset, valid_dataset=valid_dataset, **optimization_kwargs) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "What is the MSE on the test set?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.evaluate_dataset(test_dataset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Have a look a the predicted function over the 2D space"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# this cell will produce a 2D plot of your model\n",
    "x = np.arange(-lim, lim, 0.05)\n",
    "y = np.arange(-lim, lim, 0.05)\n",
    "xx, yy = np.meshgrid(x, y, sparse=False)\n",
    "Z1 = func(xx,yy)\n",
    "\n",
    "X = torch.tensor(np.array([xx.reshape(-1), yy.reshape(-1)]).T.astype(np.float32))\n",
    "Z2 = model.predict(X).reshape(xx.shape)\n",
    "\n",
    "vmin = np.min(Z1)\n",
    "vmax = np.max(Z1)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(Z1, vmin=vmin, vmax=vmax, extent=[-lim,lim,-lim,lim])\n",
    "plt.colorbar()\n",
    "plt.axis('scaled')\n",
    "plt.title(\"Ground truth\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(Z2, vmin=vmin, vmax=vmax, extent=[-lim,lim,-lim,lim])\n",
    "plt.colorbar()\n",
    "plt.axis('scaled')\n",
    "plt.title(\"Neural network\");"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2: Architecture adapted to the dataset\n",
    "Create a new model that take into account of the shape of $f$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate the new model and compare with the previous result."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2b: Learn the constant a, b\n",
    "Make the variable a and b learnable in the model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Did you learn the correct constant a and b?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e77879e7ba482baebf215f15929643f03e50a667c52f4e8743882ead31c04b9"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('oeaw-ai-summer-school-2021-CMalzwFa': pipenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}